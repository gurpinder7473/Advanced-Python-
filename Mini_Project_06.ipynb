{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurpinder7473/Advanced-Python-/blob/main/Mini_Project_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC80Evf-DQbX"
      },
      "source": [
        "# **                                            Advance Python Assignments**\n",
        "\n",
        "\n",
        "\n",
        "## **Part I: Process Automation **\n",
        "\n",
        "Q1.   Create a file that contains 1000 lines of random strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWBEoYYsT6FI"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_string(length=50):\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "def create_file_with_random_strings(filename, lines=1000):\n",
        "    with open(filename, 'w') as f:\n",
        "        for _ in range(lines):\n",
        "            f.write(generate_random_string() + '\\n')\n",
        "\n",
        "create_file_with_random_strings('random_1000_lines.txt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08DSz1h3a6fC"
      },
      "source": [
        "Q2. Create a file that contains multiple lines of random strings and file size must be 5 MB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxB0lrCTUH0h"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_line(length=100):\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length)) + '\\n'\n",
        "\n",
        "def create_file_5mb(filename='random_5MB.txt', target_size_mb=5):\n",
        "    target_size_bytes = target_size_mb * 1024 * 1024  # 5 MB in bytes\n",
        "    written_bytes = 0\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        while written_bytes < target_size_bytes:\n",
        "            line = generate_random_line()\n",
        "            f.write(line)\n",
        "            written_bytes += len(line)\n",
        "\n",
        "create_file_5mb()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvtlwCmPbUDP"
      },
      "source": [
        "Q3. Create 10 files that contains multiple lines of random strings and file size of each file must be 5 MB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy_PtUqKbaYg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import secrets\n",
        "import string\n",
        "\n",
        "NUM_FILES = 10\n",
        "TARGET_BYTES = 5 * 1024 * 1024  # 5 MiB\n",
        "LINE_LEN = 64  # characters per line\n",
        "\n",
        "POOL = string.ascii_letters + string.digits + string.punctuation\n",
        "# Use secrets.choice for cryptographically secure randomness :contentReference[oaicite:1]{index=1}\n",
        "\n",
        "def random_line(n):\n",
        "    return ''.join(secrets.choice(POOL) for _ in range(n))\n",
        "\n",
        "def generate_one(filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        while f.tell() < TARGET_BYTES:\n",
        "            line = random_line(LINE_LEN)\n",
        "            f.write(line + \"\\n\")\n",
        "            if f.tell() > TARGET_BYTES:\n",
        "                f.truncate(TARGET_BYTES)\n",
        "                break\n",
        "\n",
        "def main():\n",
        "    os.makedirs(\"random5MB_files\", exist_ok=True)\n",
        "    for i in range(1, NUM_FILES + 1):\n",
        "        fname = f\"random5MB_files/random_{i:02d}.txt\"\n",
        "        generate_one(fname)\n",
        "        size = os.path.getsize(fname)\n",
        "        print(f\"Wrote {size:,} bytes → {fname}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooruYQzocQV9"
      },
      "source": [
        "Q4.  Create 5 files of size 1GB, 2GB, 3GB, 4GB and 5GB; file contains multiple lines of random strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhiF-hVWTGjf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_line(line_length=100):\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=line_length)) + '\\n'\n",
        "\n",
        "def create_file(filename, size_gb):\n",
        "    size_bytes = size_gb * 1024 * 1024 * 1024\n",
        "    written_bytes = 0\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        while written_bytes < size_bytes:\n",
        "            line = generate_random_line()\n",
        "            f.write(line)\n",
        "            written_bytes += len(line)\n",
        "\n",
        "# Generate 5 files of 1GB to 5GB\n",
        "for i in range(1, 6):\n",
        "    create_file(f'random_file_{i}GB.txt', i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps3t2AqtfyJM"
      },
      "source": [
        "Q5.  Convert all the files of Q4 into upper case parallel one by one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDcAzdxSRqfw"
      },
      "outputs": [],
      "source": [
        "def convert_to_uppercase_sequential():\n",
        "    for i in range(1, 6):\n",
        "        input_file = f'random_file_{i}GB.txt'\n",
        "        output_file = f'uppercase_file_{i}GB.txt'\n",
        "\n",
        "        with open(input_file, 'r') as rf, open(output_file, 'w') as wf:\n",
        "            for line in rf:\n",
        "                wf.write(line.upper())\n",
        "\n",
        "convert_to_uppercase_sequential()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQCjZypWhCAH"
      },
      "source": [
        "Q6. Convert all the files of Q4 into upper case parallel using multi-threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEjvH5Z7TXWt"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "\n",
        "def convert_file_uppercase(i):\n",
        "    input_file = f'random_file_{i}GB.txt'\n",
        "    output_file = f'uppercase_parallel_file_{i}GB.txt'\n",
        "\n",
        "    with open(input_file, 'r') as rf, open(output_file, 'w') as wf:\n",
        "        for line in rf:\n",
        "            wf.write(line.upper())\n",
        "\n",
        "threads = []\n",
        "for i in range(1, 6):\n",
        "    t = threading.Thread(target=convert_file_uppercase, args=(i,))\n",
        "    threads.append(t)\n",
        "    t.start()\n",
        "\n",
        "# Wait for all threads to finish\n",
        "for t in threads:\n",
        "    t.join()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ncgTy1vhg-1"
      },
      "source": [
        "Q7. WAP to automatically download 10 images of cat from “Google Images”. [Hint: Find the package from\n",
        "pypi.org and use it]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ldYOUHrThwn"
      },
      "outputs": [],
      "source": [
        "pip install google_images_download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OTL4mYyTizY"
      },
      "outputs": [],
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "def download_cat_images():\n",
        "    response = google_images_download.googleimagesdownload()\n",
        "\n",
        "    arguments = {\n",
        "        \"keywords\": \"cat\",\n",
        "        \"limit\": 10,\n",
        "        \"print_urls\": True,\n",
        "        \"format\": \"jpg\",\n",
        "        \"output_directory\": \"downloads\",\n",
        "        \"image_directory\": \"cats\"\n",
        "    }\n",
        "\n",
        "    response.download(arguments)\n",
        "\n",
        "download_cat_images()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4Tk099nUN7k"
      },
      "source": [
        "Q8. WAP to automatically download 10 videos of “Machine Learning” from “Youtube.com”. [Hint: Find the\n",
        "package from pypi.org and use it]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JMEnbpvUR5b"
      },
      "outputs": [],
      "source": [
        "from pytube import Search, YouTube\n",
        "\n",
        "def download_machine_learning_videos(max_videos=10):\n",
        "    query = \"Machine Learning\"\n",
        "    search = Search(query)\n",
        "\n",
        "    count = 0\n",
        "    for video in search.results:\n",
        "        try:\n",
        "            yt = YouTube(video.watch_url)\n",
        "            stream = yt.streams.filter(progressive=True, file_extension='mp4').get_lowest_resolution()\n",
        "            print(f\"Downloading: {yt.title}\")\n",
        "            stream.download(output_path='videos')\n",
        "            count += 1\n",
        "            if count >= max_videos:\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download: {e}\")\n",
        "\n",
        "download_machine_learning_videos()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTjbfoVrUYqe"
      },
      "source": [
        "Q9. Convert all the videos of Q8 and convert it to audio. [Hint: Find the package from pypi.org and use it]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIf4FScFUe_9"
      },
      "outputs": [],
      "source": [
        "pip install moviepy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSxvXASTUnDu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def convert_videos_to_audio(video_folder='videos', audio_folder='audios'):\n",
        "    os.makedirs(audio_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(video_folder):\n",
        "        if filename.endswith('.mp4'):\n",
        "            video_path = os.path.join(video_folder, filename)\n",
        "            audio_path = os.path.join(audio_folder, filename.replace('.mp4', '.mp3'))\n",
        "\n",
        "            try:\n",
        "                print(f\"Converting {filename} to MP3...\")\n",
        "                video = VideoFileClip(video_path)\n",
        "                video.audio.write_audiofile(audio_path)\n",
        "                video.close()\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "convert_videos_to_audio()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TWTrCwsUpxe"
      },
      "source": [
        "Q10. Create an automated pipeline using multi-threading for:\n",
        "“Automatic Download of 100 Videos from YouTube” → “Convert it to Audio”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KHXqhc2UtEX"
      },
      "outputs": [],
      "source": [
        "pip install pytube moviepy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__6eBsDsUzpu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import threading\n",
        "from pytube import Search, YouTube\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Create necessary folders\n",
        "os.makedirs('videos', exist_ok=True)\n",
        "os.makedirs('audios', exist_ok=True)\n",
        "\n",
        "# ---------- Video Download Function ----------\n",
        "def download_video(video_url, video_index):\n",
        "    try:\n",
        "        yt = YouTube(video_url)\n",
        "        stream = yt.streams.filter(progressive=True, file_extension='mp4').get_lowest_resolution()\n",
        "        filename = f'videos/video_{video_index}.mp4'\n",
        "        print(f\"[{video_index}] Downloading: {yt.title}\")\n",
        "        stream.download(filename=filename)\n",
        "        print(f\"[{video_index}] Download complete.\")\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        print(f\"[{video_index}] Error downloading video: {e}\")\n",
        "        return None\n",
        "\n",
        "# ---------- Audio Conversion Function ----------\n",
        "def convert_to_audio(video_path, index):\n",
        "    try:\n",
        "        audio_path = f'audios/audio_{index}.mp3'\n",
        "        print(f\"[{index}] Converting to audio...\")\n",
        "        video = VideoFileClip(video_path)\n",
        "        video.audio.write_audiofile(audio_path, logger=None)\n",
        "        video.close()\n",
        "        print(f\"[{index}] Audio saved: {audio_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[{index}] Error converting video: {e}\")\n",
        "\n",
        "# ---------- Worker Thread Function ----------\n",
        "def worker(video_url, index):\n",
        "    video_path = download_video(video_url, index)\n",
        "    if video_path:\n",
        "        convert_to_audio(video_path, index)\n",
        "\n",
        "# ---------- Main Pipeline ----------\n",
        "def automated_pipeline():\n",
        "    query = \"machine learning\"\n",
        "    search = Search(query)\n",
        "    video_urls = [video.watch_url for video in search.results[:100]]\n",
        "\n",
        "    threads = []\n",
        "    for idx, url in enumerate(video_urls):\n",
        "        t = threading.Thread(target=worker, args=(url, idx + 1))\n",
        "        threads.append(t)\n",
        "        t.start()\n",
        "\n",
        "    # Wait for all threads to finish\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "\n",
        "    print(\" All videos downloaded and converted.\")\n",
        "\n",
        "automated_pipeline()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCHlxZ8xU5BF"
      },
      "source": [
        "Q11. Create an automated pipeline using multi-threading for: “Automatic Download of 500 images of Dog from\n",
        "GoogleImages” → “Rescale it to 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTPk1P3dVK5A"
      },
      "outputs": [],
      "source": [
        "pip install icrawler Pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHuyC6qQVSuW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import threading\n",
        "from PIL import Image\n",
        "from icrawler.builtin import GoogleImageCrawler\n",
        "\n",
        "# Create folders\n",
        "os.makedirs(\"dog_images_original\", exist_ok=True)\n",
        "os.makedirs(\"dog_images_resized\", exist_ok=True)\n",
        "\n",
        "# ---------- Step 1: Download Images ----------\n",
        "def download_images(keyword=\"dog\", num_images=500, folder=\"dog_images_original\"):\n",
        "    crawler = GoogleImageCrawler(storage={\"root_dir\": folder})\n",
        "    crawler.crawl(keyword=keyword, max_num=num_images)\n",
        "    print(\"Image download completed.\")\n",
        "\n",
        "# ---------- Step 2: Resize Function ----------\n",
        "def resize_image(image_path, output_folder):\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        width, height = img.size\n",
        "        resized_img = img.resize((width // 2, height // 2))\n",
        "        filename = os.path.basename(image_path)\n",
        "        resized_img.save(os.path.join(output_folder, filename))\n",
        "        print(f\"Resized: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to resize {image_path}: {e}\")\n",
        "\n",
        "# ---------- Step 3: Threaded Resizing ----------\n",
        "def resize_images_multithreaded(input_folder=\"dog_images_original\", output_folder=\"dog_images_resized\"):\n",
        "    threads = []\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            t = threading.Thread(target=resize_image, args=(image_path, output_folder))\n",
        "            threads.append(t)\n",
        "            t.start()\n",
        "\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "    print(\"All images resized.\")\n",
        "\n",
        "# ---------- Pipeline Runner ----------\n",
        "def image_pipeline():\n",
        "    download_images()  # Step 1: Download 500 dog images\n",
        "    resize_images_multithreaded()  # Step 2: Resize using threads\n",
        "\n",
        "image_pipeline()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv0DbfS_Vh_G"
      },
      "source": [
        "Q12. Create a random dataset of 100 rows and 30 columns. All the values are defined between [1,200]. Perform\n",
        "the following operations:\n",
        "(i) Replace all the values with NA in the dataset defined between [10, 60]. Print the count of number\n",
        "rows having missing values.\n",
        "(ii) Replace all the NA values with the average of the column value.\n",
        "(iii) Find the Pearson correlation among all the columns and plot heat map. Also select those columns\n",
        "having correlation <=0.7.\n",
        "(iv) Normalize all the values in the dataset between 0 and 10.\n",
        "(v) Replace all the values in the dataset with 1 if value <=0.5 else with 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCXg__JJVmim"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "df = pd.DataFrame(np.random.randint(1, 201, size=(100, 30)))\n",
        "\n",
        "df_na = df.mask(df.between(10, 60))\n",
        "rows_with_na = df_na.isnull().any(axis=1).sum()\n",
        "print(\"Rows with missing values:\", rows_with_na)\n",
        "\n",
        "df_filled = df_na.fillna(df_na.mean(numeric_only=True))\n",
        "\n",
        "corr = df_filled.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "selected_cols = [col for col in corr.columns if all(abs(corr[col][corr.columns != col]) <= 0.7)]\n",
        "df_selected = df_filled[selected_cols]\n",
        "print(\"Columns with correlation ≤ 0.7:\", selected_cols)\n",
        "\n",
        "df_normalized = (df_selected - df_selected.min()) / (df_selected.max() - df_selected.min()) * 10\n",
        "\n",
        "df_binary = (df_normalized <= 0.5).astype(int)\n",
        "print(df_binary.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW7bN7IfWAqg"
      },
      "source": [
        "Q13. Create a random dataset of 600 rows and 15 columns. All the values are defined between [-100,100].\n",
        "Perform the following operations:\n",
        "(i) Plot scatter graph between Column 5 and Column 6.\n",
        "(ii) Plot histogram of each column in single graph.\n",
        "(iii) Plot the Box plot of each column in single graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTcVYKwgWTB9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(42)\n",
        "df = pd.DataFrame(np.random.randint(-100, 101, size=(600, 15)))\n",
        "\n",
        "# (i) Scatter plot between Column 5 and Column 6\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(df[4], df[5], alpha=0.6, color='teal')\n",
        "plt.title(\"Scatter Plot: Column 5 vs Column 6\")\n",
        "plt.xlabel(\"Column 5\")\n",
        "plt.ylabel(\"Column 6\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# (ii) Histogram of each column in one graph\n",
        "df.plot(kind='hist', bins=20, alpha=0.6, figsize=(10, 6))\n",
        "plt.title(\"Histogram of All Columns\")\n",
        "plt.xlabel(\"Value Range\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# (iii) Box plot of each column in one graph\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=df, orient='v')\n",
        "plt.title(\"Box Plot of All Columns\")\n",
        "plt.xlabel(\"Columns\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIsVTz7/ocoLf7cVMDUU1l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}